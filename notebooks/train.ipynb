{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Trainable directions + CLIP Text Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "targets = \"blond hair,beard,smiling,bald,eyeglasses\"  # comma-separated list of target attributes\n",
    "cmd = [\n",
    "    \"python\", \"../modules/stylegan2-ada-pytorch/train_direction_variant_a.py\",\n",
    "    \"--network\", \"../modules/stylegan2-ada-pytorch/ffhq.pkl\",\n",
    "    \"--save-dir\", \"../outputs/training_steps_variant_a/\",\n",
    "    \"--targets\", targets\n",
    "]\n",
    "\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainable directions & step size + CLIP Text Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "targets = \"blond hair,beard,smiling,bald,eyeglasses\"  # comma-separated list of target attributes\n",
    "cmd = [\n",
    "    \"python\", \"../modules/stylegan2-ada-pytorch/train_direction_variant_b.py\",\n",
    "    \"--network\", \"../modules/stylegan2-ada-pytorch/ffhq.pkl\",\n",
    "    \"--save-dir\", \"../outputs/training_steps_variant_b/\",\n",
    "    \"--targets\", targets\n",
    "]\n",
    "\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainable directions + CLIP Image / Text Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "lambda_id = 0.8\n",
    "targets = \"blond hair,beard,smiling,bald,eyeglasses\"  # comma-separated list of target attributes\n",
    "cmd = [\n",
    "    \"python\", \"../modules/stylegan2-ada-pytorch/train_direction_variant_c.py\",\n",
    "    \"--network\", \"../modules/stylegan2-ada-pytorch/ffhq.pkl\",\n",
    "    \"--save-dir\", f\"../outputs/training_steps_variant_c_{str(lambda_id).replace('.', '')}/\",\n",
    "    \"--targets\", targets,\n",
    "    \"--lambda-id\", str(lambda_id)\n",
    "]\n",
    "\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainable directions & step size + CLIP Image / Text Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "lambda_id = 0.8\n",
    "targets = \"blond hair,beard,smiling,bald,eyeglasses\"  # comma-separated list of target attributes\n",
    "cmd = [\n",
    "    \"python\", \"../modules/stylegan2-ada-pytorch/train_direction_variant_d.py\",\n",
    "    \"--network\", \"../modules/stylegan2-ada-pytorch/ffhq.pkl\",\n",
    "    \"--save-dir\", f\"../outputs/training_steps_variant_dddd_{str(lambda_id).replace('.', '')}/\",\n",
    "    \"--targets\", targets,\n",
    "    \"--lambda-id\", str(lambda_id)\n",
    "]\n",
    "\n",
    "subprocess.run(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
